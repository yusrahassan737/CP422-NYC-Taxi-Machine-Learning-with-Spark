{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dc63d0de-a460-450e-9c66-fe2cad5526ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# All Imports\n",
    "from pyspark.sql.functions import to_timestamp, unix_timestamp, col, mean, max, hour, dayofweek, when\n",
    "from pyspark.sql.types import DoubleType, IntegerType\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import DecisionTreeRegressor, LinearRegression\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, StandardScaler\n",
    "from pyspark.ml.evaluation import RegressionEvaluator, MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "import os\n",
    "from pyspark.ml.regression import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5c22f952-407e-4e3f-b686-31ecb51d3827",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Task 1 - Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "325b4ded-317b-49be-abad-0a51f158ef53",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- VendorID: integer (nullable = true)\n |-- tpep_pickup_datetime: timestamp (nullable = true)\n |-- tpep_dropoff_datetime: timestamp (nullable = true)\n |-- passenger_count: integer (nullable = true)\n |-- trip_distance: double (nullable = true)\n |-- pickup_longitude: double (nullable = true)\n |-- pickup_latitude: double (nullable = true)\n |-- RateCodeID: integer (nullable = true)\n |-- store_and_fwd_flag: string (nullable = true)\n |-- dropoff_longitude: double (nullable = true)\n |-- dropoff_latitude: double (nullable = true)\n |-- payment_type: integer (nullable = true)\n |-- fare_amount: double (nullable = true)\n |-- extra: double (nullable = true)\n |-- mta_tax: double (nullable = true)\n |-- tip_amount: double (nullable = true)\n |-- tolls_amount: double (nullable = true)\n |-- improvement_surcharge: double (nullable = true)\n |-- total_amount: double (nullable = true)\n\n+-------+------------------+------------------+------------------+\n|summary|       fare_amount|     trip_distance|   passenger_count|\n+-------+------------------+------------------+------------------+\n|  count|            100000|            100000|            100000|\n|   mean|11.916868299999944|26.104725499999997|           1.67431|\n| stddev| 10.26160268877883| 7373.791051093258|1.3283123382836886|\n|    min|            -210.0|               0.0|                 0|\n|    max|             499.0|         2331800.0|                 6|\n+-------+------------------+------------------+------------------+\n\n+--------+--------------------+---------------------+---------------+-------------+------------------+------------------+----------+------------------+------------------+------------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+------------------+------------------+-----------+------------------+\n|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|  pickup_longitude|   pickup_latitude|RateCodeID|store_and_fwd_flag| dropoff_longitude|  dropoff_latitude|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|     trip_duration|        trip_speed|pickup_hour|pickup_day_of_week|\n+--------+--------------------+---------------------+---------------+-------------+------------------+------------------+----------+------------------+------------------+------------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+------------------+------------------+-----------+------------------+\n|       2| 2015-01-23 18:54:13|  2015-01-23 19:06:38|              2|         1.35|-74.00575256347656|40.718448638916016|         1|                 N| -73.9906005859375|40.730777740478516|           1|        9.0|  1.0|    0.5|      2.16|         0.0|                  0.3|       12.96|12.416666666666666| 6.523489932885907|         18|                 6|\n|       2| 2015-01-23 18:54:13|  2015-01-23 19:12:09|              1|         3.05|-73.97847747802734| 40.76445388793945|         1|                 N|-73.96755981445312|40.802642822265625|           1|       14.0|  1.0|    0.5|      3.16|         0.0|                  0.3|       18.96|17.933333333333334| 10.20446096654275|         18|                 6|\n|       2| 2015-01-23 18:54:13|  2015-01-23 19:18:15|              1|         2.92|-73.98060607910156|  40.7305908203125|         1|                 N|-73.99107360839844|40.759002685546875|           1|       16.5|  1.0|    0.5|       3.0|         0.0|                  0.3|        21.3|24.033333333333335|7.2898751733703175|         18|                 6|\n|       2| 2015-01-23 18:54:13|  2015-01-23 19:01:25|              1|         0.92| -73.9909896850586| 40.76044845581055|         1|                 N|-73.99089813232422|  40.7504997253418|           1|        6.0|  1.0|    0.5|      1.56|         0.0|                  0.3|        9.36|               7.2| 7.666666666666666|         18|                 6|\n|       2| 2015-01-23 18:54:13|  2015-01-23 19:27:40|              1|        17.58| -73.7891616821289| 40.64318084716797|         2|                 N|-73.97000885009766| 40.75668716430664|           2|       52.0|  0.0|    0.5|       0.0|        5.33|                  0.3|       58.13|             33.45|31.533632286995513|         18|                 6|\n+--------+--------------------+---------------------+---------------+-------------+------------------+------------------+----------+------------------+------------------+------------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+------------------+------------------+-----------+------------------+\nonly showing top 5 rows\n+--------+--------------------+---------------------+---------------+-------------+------------------+------------------+----------+------------------+------------------+------------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+------------------+------------------+-----------+------------------+---------+\n|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|  pickup_longitude|   pickup_latitude|RateCodeID|store_and_fwd_flag| dropoff_longitude|  dropoff_latitude|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|     trip_duration|        trip_speed|pickup_hour|pickup_day_of_week|high_fare|\n+--------+--------------------+---------------------+---------------+-------------+------------------+------------------+----------+------------------+------------------+------------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+------------------+------------------+-----------+------------------+---------+\n|       1| 2015-01-01 00:06:38|  2015-01-01 00:15:47|              1|          1.5|-73.97798156738281| 40.74525833129883|         1|                 N|-73.96768188476562|40.755245208740234|           1|        7.7|  0.5|    0.5|       1.8|         0.0|                  0.0|        10.8|              9.15| 9.836065573770492|          0|                 5|        0|\n|       1| 2015-01-01 00:06:40|  2015-01-01 00:27:12|              1|          1.6|-73.98135375976562| 40.75812530517578|         5|                 N|  -73.989013671875|  40.7742805480957|           2|       0.01|  0.0|    0.0|       0.0|         0.0|                  0.0|        0.31|20.533333333333335| 4.675324675324675|          0|                 5|        0|\n|       1| 2015-01-01 00:06:41|  2015-01-01 00:10:36|              4|          0.5|-73.95278930664062|40.776702880859375|         1|                 N|-73.96011352539062|  40.7765007019043|           2|        4.5|  0.5|    0.5|       0.0|         0.0|                  0.0|         5.8|3.9166666666666665| 7.659574468085106|          0|                 5|        0|\n|       1| 2015-01-01 00:06:42|  2015-01-01 00:14:24|              1|          1.4|-73.98536682128906| 40.73741149902344|         1|                 N|-73.99996185302734| 40.72705841064453|           2|        7.5|  0.5|    0.5|       0.0|         0.0|                  0.0|         8.8|               7.7|10.909090909090908|          0|                 5|        0|\n|       1| 2015-01-01 00:06:47|  2015-01-01 00:11:15|              1|          0.8|-73.99857330322266| 40.72966766357422|         1|                 N|-73.99232482910156| 40.73292922973633|           1|        5.0|  0.5|    0.5|       6.0|         0.0|                  0.0|        12.3| 4.466666666666667|10.746268656716417|          0|                 5|        0|\n+--------+--------------------+---------------------+---------------+-------------+------------------+------------------+----------+------------------+------------------+------------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+------------------+------------------+-----------+------------------+---------+\nonly showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# Part 1: Data Preparation\n",
    "\n",
    "# 1-a) Load Dataset\n",
    "df = spark.table(\"default.yellow_tripdata_2015_01\").limit(100000)\n",
    "\n",
    "df = df.withColumn(\"passenger_count\", col(\"passenger_count\").cast(\"int\"))\n",
    "df = df.withColumn(\"trip_distance\", col(\"trip_distance\").cast(\"double\"))\n",
    "df = df.withColumn(\"fare_amount\", col(\"fare_amount\").cast(\"double\"))\n",
    "df = df.withColumn(\"tip_amount\", col(\"tip_amount\").cast(\"double\"))\n",
    "df = df.withColumn(\"mta_tax\", col(\"mta_tax\").cast(\"double\"))\n",
    "df = df.withColumn(\"extra\", col(\"extra\").cast(\"double\"))\n",
    "df = df.withColumn(\"total_amount\", col(\"total_amount\").cast(\"double\"))\n",
    "df = df.withColumn(\"tolls_amount\", col(\"tolls_amount\").cast(\"double\"))\n",
    "\n",
    "df = df.withColumn(\n",
    "    \"tpep_pickup_datetime\",\n",
    "    to_timestamp(col(\"tpep_pickup_datetime\"), \"yyyy-MM-dd HH:mm:ss\")\n",
    ")\n",
    "df = df.withColumn(\n",
    "    \"tpep_dropoff_datetime\",\n",
    "    to_timestamp(col(\"tpep_dropoff_datetime\"), \"yyyy-MM-dd HH:mm:ss\")\n",
    ")\n",
    "\n",
    "df = df.withColumn(\"pickup_latitude\", col(\"pickup_latitude\").cast(\"double\"))\n",
    "df = df.withColumn(\"pickup_longitude\", col(\"pickup_longitude\").cast(\"double\"))\n",
    "df = df.withColumn(\"dropoff_latitude\", col(\"dropoff_latitude\").cast(\"double\"))\n",
    "df = df.withColumn(\"dropoff_longitude\", col(\"dropoff_longitude\").cast(\"double\"))\n",
    "df = df.withColumn(\"payment_type\", col(\"payment_type\").cast(\"int\"))\n",
    "\n",
    "# 1-b) Data Exploration & Cleaning\n",
    "df.printSchema()\n",
    "df.select(\"fare_amount\", \"trip_distance\", \"passenger_count\").describe().show()\n",
    "\n",
    "df = df.dropna(subset=[\"fare_amount\", \"trip_distance\", \"passenger_count\"])\n",
    "df = df.filter((df.fare_amount > 0) & (df.trip_distance != 0))\n",
    "\n",
    "# 1-c) Feature Engineering\n",
    "df = df.withColumn(\n",
    "    \"trip_duration\",\n",
    "    (unix_timestamp(\"tpep_dropoff_datetime\") - unix_timestamp(\"tpep_pickup_datetime\")) / 60.0\n",
    ")  # minutes\n",
    "df = df.filter(df.trip_duration > 0)\n",
    "\n",
    "df = df.withColumn(\"trip_speed\", col(\"trip_distance\") / (col(\"trip_duration\") / 60.0))  # distance/hour\n",
    "df = df.filter(df.trip_speed > 0)\n",
    "\n",
    "# Time-based features explicitly (as suggested in assignment)\n",
    "df = df.withColumn(\"pickup_hour\", hour(\"tpep_pickup_datetime\"))\n",
    "df = df.withColumn(\"pickup_day_of_week\", dayofweek(\"tpep_pickup_datetime\"))\n",
    "\n",
    "df.show(5)\n",
    "\n",
    "# 1-d) Target Variable Creation\n",
    "df = df.withColumn(\"high_fare\", when(col(\"fare_amount\") > 20, 1).otherwise(0))\n",
    "\n",
    "# 1-e) Data Splitting (70/30)\n",
    "train_df, test_df = df.randomSplit([0.7, 0.3], seed=777)\n",
    "test_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "94c8bed1-4dd8-453f-a8f3-3f150b6bba0a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+------------------------------------------------------------+\n|high_fare|prediction|features                                                    |\n+---------+----------+------------------------------------------------------------+\n|0        |0.0       |[1.0,1.0,1.5,9.15,9.836065573770492,0.0,5.0]                |\n|0        |0.0       |[2.0,1.0,1.6,20.533333333333335,4.675324675324675,0.0,5.0]  |\n|0        |0.0       |[2.0,4.0,0.5,3.9166666666666665,7.659574468085106,0.0,5.0]  |\n|0        |0.0       |[2.0,1.0,1.4,7.7,10.909090909090908,0.0,5.0]                |\n|0        |0.0       |[1.0,1.0,0.8,4.466666666666667,10.746268656716417,0.0,5.0]  |\n|1        |1.0       |[2.0,1.0,16.9,25.966666666666665,39.050064184852374,0.0,5.0]|\n|0        |0.0       |[2.0,1.0,0.3,1.95,9.23076923076923,0.0,5.0]                 |\n|0        |0.0       |[1.0,1.0,1.6,7.516666666666667,12.771618625277164,0.0,5.0]  |\n|0        |0.0       |[2.0,1.0,3.5,10.666666666666666,19.687500000000004,0.0,5.0] |\n|0        |0.0       |[2.0,3.0,1.3,4.8,16.25,0.0,5.0]                             |\n+---------+----------+------------------------------------------------------------+\nonly showing top 10 rows\nF1 Score: 0.9902\nPrecision: 0.9941\nRecall: 0.9949\n"
     ]
    }
   ],
   "source": [
    "# Pipeline 1: Decision Tree Classifier\n",
    "\n",
    "# 2-a) Define pipeline stages\n",
    "feature_cols = [\n",
    "    \"payment_type\",\n",
    "    \"passenger_count\",\n",
    "    \"trip_distance\",\n",
    "    \"trip_duration\",\n",
    "    \"trip_speed\",\n",
    "    \"pickup_hour\",\n",
    "    \"pickup_day_of_week\"\n",
    "]\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=feature_cols,\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "dt = DecisionTreeClassifier(\n",
    "    labelCol=\"high_fare\",\n",
    "    featuresCol=\"features\"\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(stages=[assembler, dt])\n",
    "\n",
    "# 2-b) Hyperparameter tuning with CrossValidator \n",
    "\n",
    "# imp note for TA: I'm using an existing Volume path for Spark ML temp storage based on my structure in the workspace\n",
    "dbutils.fs.mkdirs(\"/Volumes/workspace/default/data/cv_temp\")\n",
    "os.environ[\"SPARKML_TEMP_DFS_PATH\"] = \"/Volumes/workspace/default/data/cv_temp\"\n",
    "\n",
    "paramGrid = (\n",
    "    ParamGridBuilder()\n",
    "    .addGrid(dt.maxDepth, [3, 5, 10])             \n",
    "    .addGrid(dt.minInstancesPerNode, [1, 5, 10])  \n",
    "    .build()\n",
    ")\n",
    "\n",
    "cv_evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"high_fare\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"f1\"\n",
    ")\n",
    "\n",
    "cv = CrossValidator(\n",
    "    estimator=pipeline,\n",
    "    estimatorParamMaps=paramGrid,\n",
    "    evaluator=cv_evaluator,\n",
    "    numFolds=3,\n",
    "    parallelism=2\n",
    ")\n",
    "\n",
    "# 2-c) Model training (on training data)\n",
    "cvModel = cv.fit(train_df)\n",
    "\n",
    "#best pipeline\n",
    "best_pipeline_model = cvModel.bestModel\n",
    "\n",
    "# 2-d) Model evaluation on test data\n",
    "pred_test = best_pipeline_model.transform(test_df)\n",
    "\n",
    "pred_test.select(\"high_fare\", \"prediction\", \"features\").show(10, truncate=False)\n",
    "\n",
    "#F1\n",
    "f1_evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"high_fare\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"f1\"\n",
    ")\n",
    "f1_score = f1_evaluator.evaluate(pred_test)\n",
    "\n",
    "#Precision\n",
    "precision_evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"high_fare\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"precisionByLabel\"\n",
    ")\n",
    "precision = precision_evaluator.evaluate(pred_test)\n",
    "\n",
    "#recall\n",
    "recall_evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"high_fare\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"recallByLabel\"\n",
    ")\n",
    "recall = recall_evaluator.evaluate(pred_test)\n",
    "\n",
    "print(f\"F1 Score: {f1_score:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "\n",
    "# 2-e) Save the trained pipeline \n",
    "best_pipeline_model.write().overwrite().save(\"/Volumes/workspace/default/data/dt_high_fare_pipeline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b133d490-60b8-4088-9bf7-fc4c247634bc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best regParam: 0.01\nBest maxIter: 10\n+---------+----------+----------------------------------------+\n|high_fare|prediction|probability                             |\n+---------+----------+----------------------------------------+\n|0        |0.0       |[0.8767614432379037,0.12323855676209627]|\n|0        |0.0       |[0.8701200579501847,0.12987994204981534]|\n|0        |0.0       |[0.9114608806128656,0.08853911938713444]|\n|0        |0.0       |[0.9063710717992971,0.0936289282007029] |\n|0        |0.0       |[0.890556815687598,0.10944318431240196] |\n|1        |0.0       |[0.851470756616728,0.148529243383272]   |\n|0        |0.0       |[0.9194599477482274,0.08054005225177263]|\n|0        |0.0       |[0.8817347017197817,0.11826529828021826]|\n|0        |0.0       |[0.8988961795479969,0.10110382045200306]|\n|0        |0.0       |[0.910678044866618,0.08932195513338204] |\n+---------+----------+----------------------------------------+\nonly showing top 10 rows\nF1 Score: 0.8343\nPrecision: 0.8870\nRecall: 0.9994\nAUC: 0.9355\n"
     ]
    }
   ],
   "source": [
    "# Pipeline 2: Logistic Regression Pipeline\n",
    "\n",
    "# 3-a) Define pipeline stages\n",
    "feature_cols = [\n",
    "    \"payment_type\",\n",
    "    \"passenger_count\",\n",
    "    \"trip_distance\",\n",
    "    \"trip_duration\",\n",
    "    \"trip_speed\",\n",
    "    \"pickup_hour\",\n",
    "    \"pickup_day_of_week\"\n",
    "]\n",
    "\n",
    "assembler_lr = VectorAssembler(\n",
    "    inputCols=feature_cols,\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "logr = LogisticRegression(\n",
    "    labelCol=\"high_fare\",\n",
    "    featuresCol=\"features\"\n",
    ")\n",
    "\n",
    "pipeline_lr = Pipeline(stages=[assembler_lr, logr])\n",
    "\n",
    "# 3-b) Hyperparameter tuning with CrossValidator\n",
    "cv_tmp_path = \"/Volumes/workspace/default/data/cv_temp\"\n",
    "dbutils.fs.mkdirs(cv_tmp_path)\n",
    "os.environ[\"SPARKML_TEMP_DFS_PATH\"] = cv_tmp_path\n",
    "\n",
    "paramGrid_lr = (\n",
    "    ParamGridBuilder()\n",
    "    .addGrid(logr.regParam, [0.01, 0.1, 0.5])\n",
    "    .addGrid(logr.maxIter, [10, 50, 100])\n",
    "    .build()\n",
    ")\n",
    "\n",
    "#for CV we can optimize AUC\n",
    "binary_evaluator = BinaryClassificationEvaluator(\n",
    "    labelCol=\"high_fare\",\n",
    "    rawPredictionCol=\"rawPrediction\",\n",
    "    metricName=\"areaUnderROC\"\n",
    ")\n",
    "\n",
    "cv_lr = CrossValidator(\n",
    "    estimator=pipeline_lr,\n",
    "    estimatorParamMaps=paramGrid_lr,\n",
    "    evaluator=binary_evaluator,\n",
    "    numFolds=5,\n",
    "    parallelism=2\n",
    ")\n",
    "\n",
    "# 3-c) Train using cross-validation\n",
    "cv_lr_model = cv_lr.fit(train_df)\n",
    "\n",
    "# Best pipeline\n",
    "best_lr_pipeline = cv_lr_model.bestModel\n",
    "\n",
    "#inspect chosen hyperparameters\n",
    "best_lr = best_lr_pipeline.stages[-1]  # last stage is LogisticRegression\n",
    "print(\"Best regParam:\", best_lr.getRegParam())\n",
    "print(\"Best maxIter:\", best_lr.getMaxIter())\n",
    "\n",
    "# 3-d) Evaluate on the test set\n",
    "predictions = best_lr_pipeline.transform(test_df)\n",
    "\n",
    "predictions.select(\"high_fare\", \"prediction\", \"probability\").show(10, truncate=False)\n",
    "\n",
    "# F1. precision, recall\n",
    "f1_evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"high_fare\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"f1\"\n",
    ")\n",
    "f1_score = f1_evaluator.evaluate(predictions)\n",
    "precision_evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"high_fare\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"precisionByLabel\"\n",
    ")\n",
    "precision = precision_evaluator.evaluate(predictions)\n",
    "recall_evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"high_fare\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"recallByLabel\"\n",
    ")\n",
    "recall = recall_evaluator.evaluate(predictions)\n",
    "auc = binary_evaluator.evaluate(predictions)\n",
    "\n",
    "print(f\"F1 Score: {f1_score:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"AUC: {auc:.4f}\")\n",
    "\n",
    "# 3-e) Save the trained Logistic Regression pipeline\n",
    "best_lr_pipeline.write().overwrite().save(\"/Volumes/workspace/default/data/lr_high_fare_pipeline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "98e5995d-5690-4744-897e-8da31c89313c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Task 2: Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d3c36507-2ea4-4b15-8f87-2233902987e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- VendorID: integer (nullable = true)\n |-- tpep_pickup_datetime: timestamp (nullable = true)\n |-- tpep_dropoff_datetime: timestamp (nullable = true)\n |-- passenger_count: integer (nullable = true)\n |-- trip_distance: double (nullable = true)\n |-- pickup_longitude: double (nullable = true)\n |-- pickup_latitude: double (nullable = true)\n |-- RateCodeID: integer (nullable = true)\n |-- store_and_fwd_flag: string (nullable = true)\n |-- dropoff_longitude: double (nullable = true)\n |-- dropoff_latitude: double (nullable = true)\n |-- payment_type: integer (nullable = true)\n |-- fare_amount: double (nullable = true)\n |-- extra: double (nullable = true)\n |-- mta_tax: double (nullable = true)\n |-- tip_amount: double (nullable = true)\n |-- tolls_amount: double (nullable = true)\n |-- improvement_surcharge: double (nullable = true)\n |-- total_amount: double (nullable = true)\n\nTraining rows (regression): 69336\nTest rows (regression): 29866\n"
     ]
    }
   ],
   "source": [
    "# Part 1: Data Prep\n",
    "\n",
    "# 1-a) Load Dataset (new DataFrame)\n",
    "# Use the same table, but create a separate DataFrame for regression\n",
    "df_reg = spark.table(\"default.yellow_tripdata_2015_01\").limit(100000)\n",
    "df_reg = df_reg.withColumn(\"passenger_count\", col(\"passenger_count\").cast(\"int\"))\n",
    "df_reg = df_reg.withColumn(\"trip_distance\", col(\"trip_distance\").cast(\"double\"))\n",
    "df_reg = df_reg.withColumn(\"fare_amount\", col(\"fare_amount\").cast(\"double\"))\n",
    "df_reg = df_reg.withColumn(\n",
    "    \"tpep_pickup_datetime\",\n",
    "    to_timestamp(col(\"tpep_pickup_datetime\"), \"yyyy-MM-dd HH:mm:ss\")\n",
    ")\n",
    "df_reg = df_reg.withColumn(\n",
    "    \"tpep_dropoff_datetime\",\n",
    "    to_timestamp(col(\"tpep_dropoff_datetime\"), \"yyyy-MM-dd HH:mm:ss\")\n",
    ")\n",
    "\n",
    "df_reg.printSchema()\n",
    "\n",
    "\n",
    "# 1-b) Feature Engineering\n",
    "\n",
    "# remove missing or clearly invalid values\n",
    "df_reg = df_reg.dropna(subset=[\"fare_amount\", \"trip_distance\", \"passenger_count\"])\n",
    "df_reg = df_reg.filter((col(\"fare_amount\") > 0) & (col(\"trip_distance\") > 0))\n",
    "\n",
    "# Trip duration in minutes\n",
    "df_reg = df_reg.withColumn(\n",
    "    \"trip_duration\",\n",
    "    (unix_timestamp(\"tpep_dropoff_datetime\") - unix_timestamp(\"tpep_pickup_datetime\")) / 60.0\n",
    ")\n",
    "\n",
    "df_reg = df_reg.filter(col(\"trip_duration\") > 0)\n",
    "#filter out some outliers\n",
    "df_reg = df_reg.filter(col(\"fare_amount\") < 300)\n",
    "df_reg = df_reg.filter(col(\"trip_distance\") < 100)\n",
    "df_reg = df_reg.filter(col(\"trip_duration\") < 300)\n",
    "\n",
    "# Time-based features\n",
    "df_reg = df_reg.withColumn(\"pickup_hour\", hour(\"tpep_pickup_datetime\"))\n",
    "df_reg = df_reg.withColumn(\"pickup_day_of_week\", dayofweek(\"tpep_pickup_datetime\"))\n",
    "\n",
    "# 1-c) Train/Test Split for Regression\n",
    "train_reg_df, test_reg_df = df_reg.randomSplit([0.7, 0.3], seed=42)\n",
    "\n",
    "print(\"Training rows (regression):\", train_reg_df.count())\n",
    "print(\"Test rows (regression):\", test_reg_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ca8969de-3ce6-433c-8a3e-84413cbee25f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Linear Regression hyperparameters:\nregParam: 0.0\nmaxIter: 50\n+-----------+------------------+-------------+------------------+-----------+------------------+\n|fare_amount|prediction        |trip_distance|trip_duration     |pickup_hour|pickup_day_of_week|\n+-----------+------------------+-------------+------------------+-----------+------------------+\n|4.5        |4.6975675799699586|0.5          |3.9166666666666665|0          |5                 |\n|10.5       |8.45206841005853  |0.7          |16.633333333333333|0          |5                 |\n|10.0       |10.932618385284302|2.5          |10.816666666666666|0          |5                 |\n|8.7        |8.16296098444009  |1.0          |12.816666666666666|0          |5                 |\n|21.2       |21.073674714402898|5.3          |26.35             |0          |5                 |\n|12.2       |13.330770556957185|3.6          |10.766666666666667|0          |5                 |\n|5.0        |4.943365459334104 |0.4          |5.466666666666667 |0          |5                 |\n|14.2       |14.537026355511884|3.1          |19.733333333333334|0          |5                 |\n|7.5        |7.4919654871516705|1.2          |8.616666666666667 |0          |5                 |\n|7.5        |8.104836639077487 |1.6          |7.516666666666667 |0          |5                 |\n+-----------+------------------+-------------+------------------+-----------+------------------+\nonly showing top 10 rows\nRMSE: 2.8211\nR2 : 0.9163\n"
     ]
    }
   ],
   "source": [
    "# Pipeline 1: Linear Regression for fare_amount\n",
    "\n",
    "# 2-a) Define Pipeline Stages\n",
    "\n",
    "# Feature columns for reg\n",
    "reg_feature_cols = [\n",
    "    \"trip_distance\",\n",
    "    \"trip_duration\",\n",
    "    \"pickup_hour\",\n",
    "    \"pickup_day_of_week\",\n",
    "    \"passenger_count\"\n",
    "]\n",
    "assembler_reg = VectorAssembler(\n",
    "    inputCols=reg_feature_cols,\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "# Scale features\n",
    "scaler_reg = StandardScaler(\n",
    "    inputCol=\"features\",\n",
    "    outputCol=\"scaled_features\",\n",
    "    withMean=True,\n",
    "    withStd=True\n",
    ")\n",
    "\n",
    "# Linear Regression model\n",
    "lr_reg = LinearRegression(\n",
    "    labelCol=\"fare_amount\",\n",
    "    featuresCol=\"scaled_features\"\n",
    ")\n",
    "\n",
    "pipeline_reg = Pipeline(stages=[assembler_reg, scaler_reg, lr_reg])\n",
    "\n",
    "# 2-b) Hyperparameter Tuning with CrossValidator\n",
    "\n",
    "# same path as before\n",
    "cv_tmp_path_reg = \"/Volumes/workspace/default/data/cv_temp\"\n",
    "dbutils.fs.mkdirs(cv_tmp_path_reg)\n",
    "os.environ[\"SPARKML_TEMP_DFS_PATH\"] = cv_tmp_path_reg\n",
    "\n",
    "paramGrid_reg = (\n",
    "    ParamGridBuilder()\n",
    "    .addGrid(lr_reg.regParam, [0.0, 0.01, 0.1])\n",
    "    .addGrid(lr_reg.maxIter, [50, 100])\n",
    "    .build()\n",
    ")\n",
    "\n",
    "rmse_evaluator_cv = RegressionEvaluator(\n",
    "    labelCol=\"fare_amount\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"rmse\"\n",
    ")\n",
    "\n",
    "cv_reg = CrossValidator(\n",
    "    estimator=pipeline_reg,\n",
    "    estimatorParamMaps=paramGrid_reg,\n",
    "    evaluator=rmse_evaluator_cv,\n",
    "    numFolds=2,\n",
    "    parallelism=2\n",
    ")\n",
    "\n",
    "# 2-c) Train the model on training data\n",
    "\n",
    "cv_reg_model = cv_reg.fit(train_reg_df)\n",
    "\n",
    "#best pipeline\n",
    "best_reg_pipeline = cv_reg_model.bestModel\n",
    "best_lr_reg = best_reg_pipeline.stages[-1]\n",
    "\n",
    "print(\"Best Linear Regression hyperparameters:\")\n",
    "print(\"regParam:\", best_lr_reg.getRegParam())\n",
    "print(\"maxIter:\", best_lr_reg.getMaxIter())\n",
    "\n",
    "# 2-d) Evaluate on test data\n",
    "\n",
    "pred_reg_test = best_reg_pipeline.transform(test_reg_df)\n",
    "\n",
    "pred_reg_test.select(\n",
    "    \"fare_amount\", \"prediction\",\n",
    "    \"trip_distance\", \"trip_duration\", \"pickup_hour\", \"pickup_day_of_week\"\n",
    ").show(10, truncate=False)\n",
    "\n",
    "# RMSE, r2\n",
    "rmse_evaluator = RegressionEvaluator(\n",
    "    labelCol=\"fare_amount\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"rmse\"\n",
    ")\n",
    "rmse = rmse_evaluator.evaluate(pred_reg_test)\n",
    "r2_evaluator = RegressionEvaluator(\n",
    "    labelCol=\"fare_amount\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"r2\"\n",
    ")\n",
    "r2 = r2_evaluator.evaluate(pred_reg_test)\n",
    "\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"R2 : {r2:.4f}\")\n",
    "\n",
    "# 2-e) Save the trained regression pipeline\n",
    "best_reg_pipeline.write().overwrite().save(\"/Volumes/workspace/default/data/linreg_fare_pipeline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c240c4c9-3487-415f-b157-58d74d79418e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Random Forest hyperparameters:\nnumTrees: 50\nmaxDepth: 10\n+-----------+------------------+-------------+------------------+-----------+------------------+\n|fare_amount|prediction        |trip_distance|trip_duration     |pickup_hour|pickup_day_of_week|\n+-----------+------------------+-------------+------------------+-----------+------------------+\n|4.5        |4.749704015071958 |0.5          |3.9166666666666665|0          |5                 |\n|10.5       |10.278989160949859|0.7          |16.633333333333333|0          |5                 |\n|10.0       |10.481617869131112|2.5          |10.816666666666666|0          |5                 |\n|8.7        |9.475651170168826 |1.0          |12.816666666666666|0          |5                 |\n|21.2       |21.51177412040871 |5.3          |26.35             |0          |5                 |\n|12.2       |12.495581351502029|3.6          |10.766666666666667|0          |5                 |\n|5.0        |5.961189831525769 |0.4          |5.466666666666667 |0          |5                 |\n|14.2       |15.247679165658724|3.1          |19.733333333333334|0          |5                 |\n|7.5        |7.437869936923455 |1.2          |8.616666666666667 |0          |5                 |\n|7.5        |8.099341338736314 |1.6          |7.516666666666667 |0          |5                 |\n+-----------+------------------+-------------+------------------+-----------+------------------+\nonly showing top 10 rows\nRMSE: 3.1802\nR^2 : 0.8936\n"
     ]
    }
   ],
   "source": [
    "# Pipeline 2: Random Forest Regressor Pipeline\n",
    "\n",
    "# 2-a) Define pipeline\n",
    "rf_feature_cols = [\n",
    "    \"trip_distance\",\n",
    "    \"trip_duration\",\n",
    "    \"pickup_hour\",\n",
    "    \"pickup_day_of_week\",\n",
    "    \"passenger_count\"\n",
    "]\n",
    "assembler_rf = VectorAssembler(\n",
    "    inputCols=rf_feature_cols,\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "rf_reg = RandomForestRegressor(\n",
    "    labelCol=\"fare_amount\",\n",
    "    featuresCol=\"features\",\n",
    "    seed=42\n",
    ")\n",
    "rf_pipeline = Pipeline(stages=[assembler_rf, rf_reg])\n",
    "\n",
    "# 2-b) Hyperparameter Tuning\n",
    "\n",
    "dbutils.fs.mkdirs(\"/Volumes/workspace/default/data/cv_temp\")\n",
    "os.environ[\"SPARKML_TEMP_DFS_PATH\"] = \"/Volumes/workspace/default/data/cv_temp\"\n",
    "\n",
    "paramGrid_rf = (\n",
    "    ParamGridBuilder()\n",
    "    .addGrid(rf_reg.numTrees, [20, 50])\n",
    "    .addGrid(rf_reg.maxDepth, [5, 10])\n",
    "    .build()\n",
    ")\n",
    "\n",
    "rf_rmse_evaluator_cv = RegressionEvaluator(\n",
    "    labelCol=\"fare_amount\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"rmse\"\n",
    ")\n",
    "\n",
    "cv_rf = CrossValidator(\n",
    "    estimator=rf_pipeline,\n",
    "    estimatorParamMaps=paramGrid_rf,\n",
    "    evaluator=rf_rmse_evaluator_cv,\n",
    "    numFolds=3,\n",
    "    parallelism=2\n",
    ")\n",
    "\n",
    "# 2-c) Train on training data\n",
    "\n",
    "cv_rf_model = cv_rf.fit(train_reg_df)\n",
    "\n",
    "best_rf_pipeline = cv_rf_model.bestModel\n",
    "best_rf_model = best_rf_pipeline.stages[-1]\n",
    "\n",
    "print(\"Best Random Forest hyperparameters:\")\n",
    "print(\"numTrees:\", best_rf_model.getNumTrees)\n",
    "print(\"maxDepth:\", best_rf_model.getMaxDepth())\n",
    "\n",
    "# 2-d) Evaluate Random Forest on test data\n",
    "pred_rf_test = best_rf_pipeline.transform(test_reg_df)\n",
    "pred_rf_test.select(\n",
    "    \"fare_amount\", \"prediction\",\n",
    "    \"trip_distance\", \"trip_duration\",\n",
    "    \"pickup_hour\", \"pickup_day_of_week\"\n",
    ").show(10, truncate=False)\n",
    "rf_rmse_evaluator = RegressionEvaluator(\n",
    "    labelCol=\"fare_amount\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"rmse\"\n",
    ")\n",
    "rf_rmse = rf_rmse_evaluator.evaluate(pred_rf_test)\n",
    "rf_r2_evaluator = RegressionEvaluator(\n",
    "    labelCol=\"fare_amount\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"r2\"\n",
    ")\n",
    "rf_r2 = rf_r2_evaluator.evaluate(pred_rf_test)\n",
    "\n",
    "print(f\"RMSE: {rf_rmse:.4f}\")\n",
    "print(f\"R^2 : {rf_r2:.4f}\")\n",
    "\n",
    "# 2-d) Save trained Random Forest pipeline\n",
    "best_rf_pipeline.write().overwrite().save(\"/Volumes/workspace/default/data/rf_fare_pipeline\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Assignment 3 - Full Code",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}